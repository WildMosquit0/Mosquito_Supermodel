{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from ultralytics import YOLO  \n",
    "\n",
    "def test_validation(weights_folder, output_csv, data_path):\n",
    "    # Initialize an empty list to store results\n",
    "    metrics_data = []\n",
    "\n",
    "    # Iterate through all the model files in the folder\n",
    "    for model_file in os.listdir(weights_folder):\n",
    "        if model_file.endswith(\".pt\"):  # Ensure it's a YOLO weight file\n",
    "            model_path = os.path.join(weights_folder, model_file)\n",
    "            print(f\"Validating model: {model_file}\")\n",
    "            \n",
    "            # Load the model and validate\n",
    "            try:\n",
    "                model = YOLO(model_path)  # Load YOLO model\n",
    "                metrics = model.val(data=data_path, name = model_file)  # Perform validation\n",
    "                \n",
    "                # Append metrics to the list\n",
    "                metrics_data.append({\n",
    "                    'model': model_file,\n",
    "                    'mAP50-95': np.round(metrics.box.map, 2),\n",
    "                    'mAP50': np.round(metrics.box.map50, 2),\n",
    "                    'mAP75': np.round(metrics.box.map75, 2),\n",
    "                    'Precision': np.round(metrics.box.p, 2),\n",
    "                    'Recall': np.round(metrics.box.r, 2)\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error validating model {model_file}: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Write the results to a CSV file\n",
    "    with open(output_csv, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"model\", \"mAP50-95\", \"mAP50\", \"mAP75\", \"Precision\", \"Recall\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(metrics_data)\n",
    "\n",
    "    print(f\"Validation results saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder containing the YOLOv11 weights\n",
    "weights_folder = \"/home/wildmosquit0/git/bestModel/test_different_models\"\n",
    "output_csv = \"/home/wildmosquit0/git/bestModel/test_different_models/validation_results.csv\"\n",
    "data_path = \"/home/wildmosquit0/git/playfraound/val_models.yaml\"  # Path to the dataset file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating model: batch_3.pt\n",
      "Ultralytics 8.3.58 ðŸš€ Python-3.9.21 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "YOLO11x summary (fused): 464 layers, 56,828,179 parameters, 0 gradients, 194.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/wildmosquit0/git/model_exp/setups/seperate/640X640/labels/val... 48 images, 3 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:00<00:00, 835.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/wildmosquit0/git/model_exp/setups/seperate/640X640/labels/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         48        268      0.808      0.619      0.741      0.317\n",
      "Speed: 1.9ms preprocess, 49.6ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/batch_3.pt3\u001b[0m\n",
      "Validating model: sahi_l_1_more_300e_200.pt\n",
      "Ultralytics 8.3.58 ðŸš€ Python-3.9.21 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "YOLO11l summary (fused): 464 layers, 25,280,083 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/wildmosquit0/git/model_exp/setups/seperate/640X640/labels/val.cache... 48 images, 3 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         48        268       0.56      0.634      0.609      0.259\n",
      "Speed: 3.2ms preprocess, 31.3ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/sahi_l_1_more_300e_200.pt3\u001b[0m\n",
      "Validating model: sahi_l_1.pt\n",
      "Ultralytics 8.3.58 ðŸš€ Python-3.9.21 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "YOLO11l summary (fused): 464 layers, 25,280,083 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/wildmosquit0/git/model_exp/setups/seperate/640X640/labels/val.cache... 48 images, 3 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         48        268      0.679      0.701      0.667      0.254\n",
      "Speed: 2.0ms preprocess, 26.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/sahi_l_1.pt3\u001b[0m\n",
      "Validating model: sahi_l_1_more_300e.pt\n",
      "Ultralytics 8.3.58 ðŸš€ Python-3.9.21 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "YOLO11l summary (fused): 464 layers, 25,280,083 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/wildmosquit0/git/model_exp/setups/seperate/640X640/labels/val.cache... 48 images, 3 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         48        268      0.661       0.66       0.67      0.252\n",
      "Speed: 2.0ms preprocess, 30.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/sahi_l_1_more_300e.pt3\u001b[0m\n",
      "Validating model: 28.01.pt\n",
      "Ultralytics 8.3.58 ðŸš€ Python-3.9.21 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "YOLO11l summary (fused): 464 layers, 25,280,083 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/wildmosquit0/git/model_exp/setups/seperate/640X640/labels/val.cache... 48 images, 3 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         48        268      0.548      0.627      0.616      0.268\n",
      "Speed: 2.3ms preprocess, 31.4ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/28.01.pt3\u001b[0m\n",
      "Validation results saved to /home/wildmosquit0/git/bestModel/test_different_models/validation_results.csv\n"
     ]
    }
   ],
   "source": [
    "test_validation(weights_folder,output_csv,data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mval(data\u001b[38;5;241m=\u001b[39mdata_path, name \u001b[38;5;241m=\u001b[39m model_file)  \u001b[38;5;66;03m# Perform validation\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
