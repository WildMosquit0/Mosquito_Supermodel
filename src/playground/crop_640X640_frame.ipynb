{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crop images and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input_images'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 107\u001b[0m\n\u001b[1;32m    103\u001b[0m             file\u001b[38;5;241m.\u001b[39mwritelines(new_annotations)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Loop through all images in the folder\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;66;03m# File paths\u001b[39;00m\n\u001b[1;32m    110\u001b[0m         image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_folder, filename)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input_images'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Parameters\n",
    "input_folder = \"input_images\"  # Folder containing images and annotations\n",
    "output_folder = \"output_images\"  # Folder to save cropped images and annotations\n",
    "crop_width = 640\n",
    "crop_height = 640\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Global variables for mouse callback\n",
    "crop_start = None\n",
    "fixed_crop_box = None\n",
    "\n",
    "\n",
    "# Mouse callback function\n",
    "def draw_fixed_rectangle(event, x, y, flags, param):\n",
    "    global crop_start, fixed_crop_box\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # When the left mouse button is clicked, set the starting point for the crop\n",
    "        crop_start = (x, y)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP and crop_start:\n",
    "        # Finalize the fixed rectangle on mouse release\n",
    "        x1, y1 = crop_start\n",
    "        x2 = x1 + crop_width\n",
    "        y2 = y1 + crop_height\n",
    "\n",
    "        # Ensure the rectangle doesn't exceed the image boundaries\n",
    "        img_height, img_width = param.shape[:2]\n",
    "        x2 = min(x2, img_width)\n",
    "        y2 = min(y2, img_height)\n",
    "        x1 = max(0, x1)\n",
    "        y1 = max(0, y1)\n",
    "\n",
    "        fixed_crop_box = (x1, y1, x2, y2)\n",
    "\n",
    "\n",
    "# Function to process a single image and its annotation\n",
    "def process_image(image_path, annotation_path, output_image_path, output_annotation_path):\n",
    "    global fixed_crop_box\n",
    "\n",
    "    # Open the image with OpenCV\n",
    "    img = cv2.imread(image_path)\n",
    "    img_height, img_width = img.shape[:2]\n",
    "    img_copy = img.copy()\n",
    "\n",
    "    # Display the image and allow the user to draw the fixed crop box\n",
    "    cv2.imshow(\"Draw Fixed Crop Box\", img)\n",
    "    cv2.setMouseCallback(\"Draw Fixed Crop Box\", draw_fixed_rectangle, param=img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Ensure a crop box was defined\n",
    "    if not fixed_crop_box:\n",
    "        print(f\"Skipping {image_path}: No crop box defined.\")\n",
    "        return\n",
    "\n",
    "    # Crop the image\n",
    "    x1, y1, x2, y2 = fixed_crop_box\n",
    "    cropped_img = img_copy[y1:y2, x1:x2]\n",
    "    cv2.imwrite(output_image_path, cropped_img)\n",
    "\n",
    "    # Adjust YOLO annotations\n",
    "    if os.path.exists(annotation_path):\n",
    "        with open(annotation_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        new_annotations = []\n",
    "        for line in lines:\n",
    "            class_id, x_center, y_center, width, height = map(float, line.split())\n",
    "\n",
    "            # Convert normalized to absolute coordinates\n",
    "            x_center_abs = x_center * img_width\n",
    "            y_center_abs = y_center * img_height\n",
    "            width_abs = width * img_width\n",
    "            height_abs = height * img_height\n",
    "\n",
    "            # Skip annotations outside the crop box\n",
    "            if x_center_abs < x1 or x_center_abs > x2 or y_center_abs < y1 or y_center_abs > y2:\n",
    "                continue\n",
    "\n",
    "            # Adjust coordinates for cropping\n",
    "            x_center_abs -= x1\n",
    "            y_center_abs -= y1\n",
    "\n",
    "            # Convert back to normalized coordinates for the cropped size\n",
    "            new_img_width = x2 - x1\n",
    "            new_img_height = y2 - y1\n",
    "            x_center_new = x_center_abs / new_img_width\n",
    "            y_center_new = y_center_abs / new_img_height\n",
    "            width_new = width_abs / new_img_width\n",
    "            height_new = height_abs / new_img_height\n",
    "\n",
    "            # Save the adjusted annotation\n",
    "            new_annotations.append(f\"{int(class_id)} {x_center_new:.6f} {y_center_new:.6f} {width_new:.6f} {height_new:.6f}\\n\")\n",
    "\n",
    "        # Write the new annotations to a file\n",
    "        with open(output_annotation_path, \"w\") as file:\n",
    "            file.writelines(new_annotations)\n",
    "\n",
    "\n",
    "# Loop through all images in the folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # File paths\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        annotation_path = os.path.join(input_folder, os.path.splitext(filename)[0] + \".txt\")\n",
    "        output_image_path = os.path.join(output_folder, filename)\n",
    "        output_annotation_path = os.path.join(output_folder, os.path.splitext(filename)[0] + \".txt\")\n",
    "\n",
    "        # Process the image and annotation\n",
    "        process_image(image_path, annotation_path, output_image_path, output_annotation_path)\n",
    "\n",
    "print(\"All images and annotations processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop movie without annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Cropped video saved at: /home/bohbot/Evyatar/exp/Joni_showoff/nectar/joni_640.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def crop_video(input_path, output_path):\n",
    "    # Open the video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # Read the first frame to select ROI\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read the first frame.\")\n",
    "        return\n",
    "\n",
    "    # Let the user draw a rectangular ROI on the first frame\n",
    "    # selectROI returns (x, y, w, h)\n",
    "    r = cv2.selectROI(\"Select Crop Region\", frame, fromCenter=False, showCrosshair=True)\n",
    "    cv2.destroyWindow(\"Select Crop Region\")\n",
    "\n",
    "    x, y, w, h = r\n",
    "\n",
    "    # Get video parameters\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # FourCC is a 4-byte code used to specify the video codec\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # or 'XVID', 'AVC1', etc.\n",
    "\n",
    "    # Create a VideoWriter to write the cropped frames\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))\n",
    "\n",
    "    # Process the already-read first frame\n",
    "    cropped_first_frame = frame[y:y+h, x:x+w]\n",
    "    out.write(cropped_first_frame)\n",
    "\n",
    "    # Loop over the rest of the frames\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        cropped_frame = frame[y:y+h, x:x+w]\n",
    "        out.write(cropped_frame)\n",
    "\n",
    "    # Release everything\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Cropped video saved at: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_video = \"/home/bohbot/Evyatar/exp/Joni_showoff/nectar/joni.mp4\"\n",
    "    output_video = \"/home/bohbot/Evyatar/exp/Joni_showoff/nectar/joni_640.mp4\"\n",
    "    crop_video(input_video, output_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/bohbot/Evyatar/runs/detect/BFv112/weights/best.pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "super_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
