{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Be sure current working directory is 'demo/' folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import required functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sahi.slicing import slice_coco\n",
    "from sahi.utils.file import load_json\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import shutil\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = ['png', 'jpg', 'jpeg', 'bmp', 'gif', 'tiff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/home/bohbot/ultralytics/datasets/mos/all_mos_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_paths = []\n",
    "all_annot_paths = []\n",
    "\n",
    "for file in glob.iglob(f\"{source_dir}/*/*/*\", recursive=True):\n",
    "    if file.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif', 'tiff')):\n",
    "        all_images_paths.append(file)\n",
    "        txt_path = file.replace('images', 'labels').split('.')[0] + '.txt'\n",
    "        if os.path.exists(txt_path):\n",
    "            all_annot_paths.append(txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"found {len(all_annot_paths)} annotations and {len(all_images_paths)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path, large_files_dir):\n",
    "    try:\n",
    "        with Image.open(file_path) as img:\n",
    "            width, height = img.size\n",
    "            if width > 1000 or height > 1000:\n",
    "                shutil.copy(file_path, large_files_dir)\n",
    "                txt_file = os.path.splitext(file_path)[0] + '.txt'\n",
    "                if os.path.exists(txt_file):\n",
    "                    shutil.copy(txt_file, large_files_dir)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def copy_large_images(source_dir, large_files_dir):\n",
    "    os.makedirs(large_files_dir, exist_ok=True)\n",
    "    with ThreadPoolExecutor(max_workers=multiprocessing.cpu_count()-2) as executor:\n",
    "        for root, _, files in os.walk(source_dir):\n",
    "            file_paths = [os.path.join(root, file) for file in files if file.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif', 'tiff'))]\n",
    "            executor.map(process_file, file_paths, [large_files_dir] * len(file_paths))\n",
    "\n",
    "def split_dataset(large_files_dir, batch_output_dir, batch_size):\n",
    "    os.makedirs(batch_output_dir, exist_ok=True)\n",
    "    files = sorted(os.listdir(large_files_dir))\n",
    "    image_files = [f for f in files if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "    for idx, image_file in enumerate(image_files):\n",
    "        batch_number = idx // batch_size + 1\n",
    "        batch_folder = os.path.join(batch_output_dir, f\"batch_{batch_number}\")\n",
    "        os.makedirs(batch_folder, exist_ok=True)\n",
    "        shutil.move(os.path.join(large_files_dir, image_file), batch_folder)\n",
    "        txt_file = os.path.splitext(image_file)[0] + '.txt'\n",
    "        txt_path = os.path.join(large_files_dir, txt_file)\n",
    "        if os.path.exists(txt_path):\n",
    "            shutil.move(txt_path, batch_folder)\n",
    "\n",
    "def copy_and_split_large_images(source_dir, large_files_dir, batch_output_dir, batch_size):\n",
    "    copy_large_images(source_dir, large_files_dir)\n",
    "    split_dataset(large_files_dir, batch_output_dir, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory_or_paths = '/home/bohbot/Evyatar/git/crop_sahi/data' # folder with both images and txt files\n",
    "large_files_directory = '/home/bohbot/Evyatar/git/crop_sahi/large_files' # copies only the large images to a different folder\n",
    "batch_output_directory = '/home/bohbot/Evyatar/git/crop_sahi/batches' # where to save the crops\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_and_split_large_images(source_directory_or_paths, large_files_directory, batch_output_directory, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preslice - filter images that are more than 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "\n",
    "def copy_and_split_large_images(source_dir, large_files_dir, batch_output_dir, batch_size):\n",
    "    \"\"\"\n",
    "    Copies large images (height or width > 1000) and their associated .txt files to a target directory,\n",
    "    then splits them into batches, ensuring annotations are moved along with the images.\n",
    "\n",
    "    Args:\n",
    "        source_dir (str): Path to the source directory containing images and .txt files.\n",
    "        large_files_dir (str): Path to the directory for storing large files.\n",
    "        batch_output_dir (str): Path to the directory for storing batches.\n",
    "        batch_size (int): Number of images per batch.\n",
    "    \"\"\"\n",
    "    # Step 1: Copy large images and their associated .txt files\n",
    "    if not os.path.exists(large_files_dir):\n",
    "        os.makedirs(large_files_dir)\n",
    "\n",
    "    # Filter and copy large images and their .txt files\n",
    "    for root, _, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        width, height = img.size\n",
    "\n",
    "                        if width > 1000 or height > 1000:\n",
    "                            # Copy the image\n",
    "                            shutil.copy(file_path, large_files_dir)\n",
    "\n",
    "                            # Copy the corresponding .txt file\n",
    "                            txt_file = os.path.splitext(file)[0] + '.txt'\n",
    "                            txt_file_path = os.path.join(root, txt_file)\n",
    "                            if os.path.exists(txt_file_path):\n",
    "                                shutil.copy(txt_file_path, large_files_dir)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    print(f\"Large files copied to {large_files_dir}\")\n",
    "\n",
    "    # Step 2: Split the dataset into batches\n",
    "    def split_dataset(source_dir, output_dir, batch_size):\n",
    "        files = sorted(os.listdir(source_dir))\n",
    "        image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        for idx, image_file in enumerate(image_files):\n",
    "            batch_number = idx // batch_size + 1\n",
    "            batch_folder = os.path.join(output_dir, f\"batch_{batch_number}\")\n",
    "            os.makedirs(batch_folder, exist_ok=True)\n",
    "\n",
    "            # Move the image to the batch folder\n",
    "            image_path = os.path.join(source_dir, image_file)\n",
    "            shutil.move(image_path, batch_folder)\n",
    "\n",
    "            # Move the corresponding .txt file if it exists\n",
    "            txt_file = os.path.splitext(image_file)[0] + '.txt'\n",
    "            txt_file_path = os.path.join(source_dir, txt_file)\n",
    "            if os.path.exists(txt_file_path):\n",
    "                shutil.move(txt_file_path, batch_folder)\n",
    "\n",
    "        print(f\"Dataset split into batches of size {batch_size}\")\n",
    "\n",
    "    split_dataset(large_files_dir, batch_output_dir, batch_size)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "source_directory = '/home/bohbot/Evyatar/git/crop_sahi/data'\n",
    "large_files_directory = '/home/bohbot/Evyatar/git/crop_sahi/large_files'\n",
    "batch_output_directory = '/home/bohbot/Evyatar/git/crop_sahi/batches'\n",
    "batch_size = 1000\n",
    "\n",
    "copy_and_split_large_images(source_directory, large_files_directory, batch_output_directory, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rresponding .txt file\n",
    "                            txt_file = os.path.splitext(file)[0] + '.txt'\n",
    "                            txt_file_path = os.path.join(root, txt_file)\n",
    "                            if os.path.exists(txt_file_path):\n",
    "                                shutil.copy(txt_file_path, large_files_dir)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    print(f\"Large files copied to {large_files_dir}\")\n",
    "\n",
    "    # Step 2: Split the dataset into batches\n",
    "    def split_dataset(source_dir, output_dir, batch_size):\n",
    "        files = sorted(os.listdir(source_dir))\n",
    "        image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        for idx, image_file in enumerate(image_files):\n",
    "            batch_number = idx // batch_size + 1\n",
    "            batch_folder = os.path.join(output_dir, f\"batch_{batch_number}\")\n",
    "            os.makedirs(batch_folder, exist_ok=True)\n",
    "\n",
    "            # Move the image to the batch folder\n",
    "            image_path = os.path.join(source_dir, image_file)\n",
    "            shutil.move(image_path, batch_folder)\n",
    "\n",
    "            # Move the corresponding .txt file if it exists\n",
    "            txt_file = os.path.splitext(image_file)[0] + '.txt'\n",
    "            txt_file_path = os.path.join(source_dir, txt_file)\n",
    "            if os.path.exists(txt_file_path):\n",
    "                shutil.move(txt_file_path, batch_folder)\n",
    "\n",
    "        print(f\"Dataset split into batches of size {batch_size}\")\n",
    "\n",
    "    split_dataset(large_files_dir, batch_output_dir, batch_size)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "source_directory = '/home/bohbot/Evyatar/git/crop_sahi/data'\n",
    "large_files_directory = '/home/bohbot/Evyatar/git/crop_sahi/large_files'\n",
    "batch_output_directory = '/home/bohbot/Evyatar/git/crop_sahi/batches'\n",
    "batch_size = 1000\n",
    "\n",
    "copy_and_split_large_images(source_directory, large_files_directory, batch_output_directory, batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. convert yolo annotations to coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "# YOLO to COCO Conversion Script\n",
    "def convert_yolo_to_coco(yolo_annotations_dir, images_dir, output_json_path):\n",
    "    # Initialize COCO format structure\n",
    "    coco_format = {\n",
    "        \"images\": [],\n",
    "        \"categories\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "\n",
    "    # Define categories dynamically or manually\n",
    "    category_mapping = {}\n",
    "    annotation_id = 1\n",
    "\n",
    "    # Process image files and corresponding annotations\n",
    "    for image_filename in os.listdir(images_dir):\n",
    "        if not image_filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(images_dir, image_filename)\n",
    "        annotation_filename = os.path.splitext(image_filename)[0] + \".txt\"\n",
    "        annotation_path = os.path.join(yolo_annotations_dir, annotation_filename)\n",
    "\n",
    "        # Check if annotation file exists\n",
    "        if not os.path.exists(annotation_path):\n",
    "            print(f\"Annotation file missing for image: {image_filename}\")\n",
    "            continue\n",
    "\n",
    "        # Read image to get dimensions\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Unable to read image: {image_filename}\")\n",
    "            continue\n",
    "\n",
    "        height, width, _ = image.shape\n",
    "        image_id = len(coco_format[\"images\"]) + 1\n",
    "\n",
    "        # Add image info to COCO structure\n",
    "        coco_format[\"images\"].append({\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": image_filename,\n",
    "            \"height\": height,\n",
    "            \"width\": width\n",
    "        })\n",
    "\n",
    "        # Parse YOLO annotations\n",
    "        with open(annotation_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                line_data = line.strip().split()\n",
    "                if len(line_data) < 5:\n",
    "                    print(f\"Invalid annotation in file: {annotation_filename}\")\n",
    "                    continue\n",
    "\n",
    "                category_id = int(line_data[0])\n",
    "                x_center, y_center, bbox_width, bbox_height = map(float, line_data[1:])\n",
    "\n",
    "                # Update category mapping dynamically\n",
    "                if category_id not in category_mapping:\n",
    "                    category_mapping[category_id] = f\"category_{category_id}\"\n",
    "                    coco_format[\"categories\"].append({\n",
    "                        \"id\": category_id,\n",
    "                        \"name\": category_mapping[category_id],\n",
    "                        \"supercategory\": \"none\"\n",
    "                    })\n",
    "\n",
    "                # Convert YOLO to COCO bbox format\n",
    "                x_min = (x_center - bbox_width / 2) * width\n",
    "                y_min = (y_center - bbox_height / 2) * height\n",
    "                bbox_width *= width\n",
    "                bbox_height *= height\n",
    "\n",
    "                # Add annotation to COCO structure\n",
    "                coco_format[\"annotations\"].append({\n",
    "                    \"id\": annotation_id,\n",
    "                    \"image_id\": image_id,\n",
    "                    \"category_id\": category_id,\n",
    "                    \"bbox\": [x_min, y_min, bbox_width, bbox_height],\n",
    "                    \"area\": bbox_width * bbox_height,\n",
    "                    \"iscrowd\": 0\n",
    "                })\n",
    "                annotation_id += 1\n",
    "\n",
    "    # Save COCO annotations to JSON file\n",
    "    with open(output_json_path, \"w\") as json_file:\n",
    "        json.dump(coco_format, json_file, indent=4)\n",
    "\n",
    "    print(f\"COCO annotations successfully saved to {output_json_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted(os.listdir(batch_output_directory)):\n",
    "        batch = os.path.join(batch_output_directory,i)\n",
    "        yolo_dir = img_dir = batch\n",
    "        json_out = os.path.join(batch, \"coco_annotations.json\")\n",
    "        convert_yolo_to_coco(yolo_dir, img_dir, json_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Slicing COCO Dataset into Grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To slice a COCO dataset annoations an images, we need to specify slice parameters. In this example we will ice images into 256x256 grids overlap ratio of 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted(os.listdir(batch_output_directory)):\n",
    "    batch = os.path.join(batch_output_directory,i)\n",
    "\n",
    "    json_out = os.path.join(batch, \"coco_annotations.json\")\n",
    "    \n",
    "    sliced_dir = os.path.join(batch,\"sliced/\")\n",
    "\n",
    "    coco_dict, coco_path = slice_coco(\n",
    "        coco_annotation_file_path=json_out,\n",
    "        image_dir=batch,\n",
    "        output_coco_annotation_file_name=\"sliced\",\n",
    "        ignore_negative_samples=False,\n",
    "        output_dir=sliced_dir,\n",
    "        slice_height=640,\n",
    "        slice_width=640,\n",
    "        overlap_height_ratio=0.2,\n",
    "        overlap_width_ratio=0.2,\n",
    "        min_area_ratio=0.1,\n",
    "        verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert back to yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sahi.utils.coco import Coco\n",
    "\n",
    "for i in sorted(os.listdir(batch_output_directory)):\n",
    "  batch = os.path.join(batch_output_directory,i)\n",
    "    \n",
    "  sliced_dir = os.path.join(batch,\"sliced/\")\n",
    "  print(sliced_dir)\n",
    "  json_sliced = os.path.join(sliced_dir,\"sliced_coco.json\")\n",
    "  # init Coco object\n",
    "  coco = Coco.from_coco_dict_or_path(json_sliced, image_dir=sliced_dir)\n",
    "\n",
    "  # export converted YoloV5 formatted dataset into given output_dir with a 85% train/15% val split\n",
    "  coco.export_as_yolov5(\n",
    "    output_dir=os.path.join(source_directory,\"sliced_images_with_yolo_format\"),\n",
    "    train_split_rate=1,\n",
    "      disable_symlink=True\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize sliced annotations on sliced images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(4, 5, figsize=(13,13))\n",
    "img_ind = 0\n",
    "for row_ind in range(4):\n",
    "    for column_ind in range(5):\n",
    "        # read image\n",
    "        img = Image.open(\"demo_data/sliced/\" + coco_dict[\"images\"][img_ind][\"file_name\"]).convert('RGBA')\n",
    "        # iterate over all annotations\n",
    "        for ann_ind in range(len(coco_dict[\"annotations\"])):\n",
    "            # find annotations that belong the selected image\n",
    "            if coco_dict[\"annotations\"][ann_ind][\"image_id\"] == coco_dict[\"images\"][img_ind][\"id\"]:\n",
    "                # convert coco bbox to pil bbox\n",
    "                xywh = coco_dict[\"annotations\"][ann_ind][\"bbox\"]\n",
    "                xyxy = [xywh[0], xywh[1], xywh[0]+xywh[2], xywh[1]+xywh[3]]\n",
    "                # visualize bbox over image\n",
    "                ImageDraw.Draw(img, 'RGBA').rectangle(xyxy, width=5)\n",
    "            axarr[row_ind, column_ind].imshow(img)\n",
    "        img_ind += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "super_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
