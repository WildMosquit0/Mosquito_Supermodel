{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Be sure current working directory is 'demo/' folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import required functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sahi.slicing import slice_coco\n",
    "from sahi.utils.file import load_json\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import shutil\n",
    "import multiprocessing\n",
    "from sahi.utils.coco import Coco\n",
    "\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "from dask import bag as db\n",
    "\n",
    "import json\n",
    "import cv2\n",
    "import uuid\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train_source = '/home/bohbot/ultralytics/datasets/mos/all_mos_new/images/train'\n",
    "images_val_source = '/home/bohbot/ultralytics/datasets/mos/all_mos_new/images/val'\n",
    "labels_train_source = '/home/bohbot/ultralytics/datasets/mos/all_mos_new/labels/train'\n",
    "labels_val_source = '/home/bohbot/ultralytics/datasets/mos/all_mos_new/labels/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_paths = (\n",
    "    [image_path for image_path in glob.iglob(f\"{images_train_source}/*\") \n",
    "     if image_path.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff'))] +\n",
    "    [image_path for image_path in glob.iglob(f\"{images_val_source}/*\") \n",
    "     if image_path.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff'))]\n",
    ")\n",
    "\n",
    "all_annots_paths = (\n",
    "    [annot_path for annot_path in glob.iglob(f\"{labels_train_source}/*\") \n",
    "     if annot_path.endswith('txt')] +\n",
    "    [annot_path for annot_path in glob.iglob(f\"{labels_val_source}/*\") \n",
    "     if annot_path.endswith('txt')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_dict = {\n",
    "    os.path.splitext(os.path.basename(annot_path))[0]: annot_path\n",
    "    for annot_path in all_annots_paths if 'test' not in annot_path\n",
    "}\n",
    "\n",
    "image_annot_paths = [\n",
    "    (image_path, annot_dict[os.path.splitext(os.path.basename(image_path))[0]])\n",
    "    for image_path in all_image_paths\n",
    "    if os.path.splitext(os.path.basename(image_path))[0] in annot_dict\n",
    "]\n",
    "\n",
    "len(image_annot_paths), image_annot_paths[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_paths, large_files_dir):\n",
    "    try:\n",
    "        image_path, annot_path = file_paths\n",
    "\n",
    "        if not os.path.exists(image_path) or not os.path.exists(annot_path):\n",
    "            print(f\"Missing file: {image_path} or {annot_path}\")\n",
    "            return\n",
    "\n",
    "        with Image.open(image_path) as img:\n",
    "            width, height = img.size\n",
    "            if width > 1000 or height > 1000:\n",
    "                shutil.copy(image_path, large_files_dir)\n",
    "                shutil.copy(annot_path, large_files_dir)\n",
    "            else:\n",
    "                return\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_paths}: {e}\")\n",
    "\n",
    "\n",
    "def copy_list(image_annot_paths, large_files_dir):\n",
    "    os.makedirs(large_files_dir, exist_ok=True)\n",
    "    copied_count = 0\n",
    "    for file_paths in tqdm(image_annot_paths):\n",
    "        process_file(file_paths, large_files_dir)\n",
    "        copied_count += 1\n",
    "    print(f\"Total files copied: {copied_count}\")\n",
    "\n",
    "def copy_large_images(image_annot_paths, large_files_dir):\n",
    "    copied_count = 0\n",
    "    with ThreadPoolExecutor(max_workers=multiprocessing.cpu_count()-2) as executor:\n",
    "        results = list(executor.map(\n",
    "            lambda x: process_file(x, large_files_dir),\n",
    "            image_annot_paths\n",
    "        ))\n",
    "    print(f\"Total files copied: {copied_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory_or_paths = image_annot_paths # folder with both images and txt files\n",
    "# large_files_directory = '/home/bohbot/Evyatar/git/crop_sahi/large_files' # copies only the large images to a different folder\n",
    "batch_output_directory = '/home/bohbot/Evyatar/git/crop_sahi/large_images/images' # where to save the crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_list(image_annot_paths, batch_output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. convert yolo annotations to coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(args):\n",
    "    image_filename, images_dir, yolo_annotations_dir = args[:3]\n",
    "    category_mapping = args[3]\n",
    "\n",
    "    image_path = os.path.join(images_dir, image_filename)\n",
    "    annotation_filename = os.path.splitext(image_filename)[0] + \".txt\"\n",
    "    annotation_path = os.path.join(yolo_annotations_dir, annotation_filename)\n",
    "\n",
    "    if not os.path.exists(annotation_path):\n",
    "        return None, None, None\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return None, None, None\n",
    "\n",
    "    height, width, _ = image.shape\n",
    "    image_id = hash(image_filename)\n",
    "\n",
    "    image_data = {\n",
    "        \"id\": image_id,\n",
    "        \"file_name\": image_filename,\n",
    "        \"height\": height,\n",
    "        \"width\": width\n",
    "    }\n",
    "\n",
    "    annotations = []\n",
    "    categories = []\n",
    "\n",
    "    with open(annotation_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line_data = line.strip().split()\n",
    "            if len(line_data) < 5:\n",
    "                continue\n",
    "\n",
    "            category_id = int(line_data[0])\n",
    "            x_center, y_center, bbox_width, bbox_height = map(float, line_data[1:])\n",
    "\n",
    "            if category_id not in category_mapping:\n",
    "                category_mapping[category_id] = f\"category_{category_id}\"\n",
    "                categories.append({\n",
    "                    \"id\": category_id,\n",
    "                    \"name\": category_mapping[category_id],\n",
    "                    \"supercategory\": \"none\"\n",
    "                })\n",
    "\n",
    "            x_min = (x_center - bbox_width / 2) * width\n",
    "            y_min = (y_center - bbox_height / 2) * height\n",
    "            bbox_width *= width\n",
    "            bbox_height *= height\n",
    "\n",
    "            annotations.append({\n",
    "                \"id\": len(annotations) + 1,\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": category_id,\n",
    "                \"bbox\": [x_min, y_min, bbox_width, bbox_height],\n",
    "                \"area\": bbox_width * bbox_height,\n",
    "                \"iscrowd\": 0\n",
    "            })\n",
    "\n",
    "    return annotations, image_data, categories\n",
    "\n",
    "\n",
    "def convert_yolo_to_coco(yolo_annotations_dir, images_dir, output_json_path):\n",
    "    os.makedirs(output_json_path, exist_ok=True)\n",
    "    coco_format = {\"images\": [], \"categories\": [], \"annotations\": []}\n",
    "    category_mapping = {}\n",
    "\n",
    "    image_filenames = [\n",
    "        f for f in os.listdir(images_dir)\n",
    "        if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))\n",
    "    ]\n",
    "\n",
    "    args = [\n",
    "        (image_filename, images_dir, yolo_annotations_dir, category_mapping)\n",
    "        for image_filename in image_filenames\n",
    "    ]\n",
    "\n",
    "    with Pool(processes=os.cpu_count()-2) as pool:\n",
    "        results = list(\n",
    "            tqdm(pool.imap(process_image, args), total=len(args), desc=\"Processing images\")\n",
    "        )\n",
    "\n",
    "    for annotations, image_data, categories in results:\n",
    "        if annotations and image_data:\n",
    "            coco_format[\"annotations\"].extend(annotations)\n",
    "            coco_format[\"images\"].append(image_data)\n",
    "        if categories:\n",
    "            coco_format[\"categories\"].extend(categories)\n",
    "\n",
    "    category_ids = set()\n",
    "    unique_categories = []\n",
    "    for category in coco_format[\"categories\"]:\n",
    "        if category[\"id\"] not in category_ids:\n",
    "            category_ids.add(category[\"id\"])\n",
    "            unique_categories.append(category)\n",
    "    coco_format[\"categories\"] = unique_categories\n",
    "\n",
    "    with open(f\"{output_json_path}/coco_annotations.json\", \"w\") as json_file:\n",
    "        json.dump(coco_format, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_annotations_path = f\"{batch_output_directory.replace('/images','/coco')}\"\n",
    "sliced_images_path = f\"{batch_output_directory.replace('/images','/sliced')}\"\n",
    "temp_image_dir = f\"{batch_output_directory.replace('/images','/temp_processing')}\"\n",
    "yolo_format_dir = f\"{batch_output_directory.replace('/images','/yolo_format')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_yolo_to_coco(batch_output_directory, batch_output_directory, coco_annotations_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Slicing COCO Dataset into Grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To slice a COCO dataset annoations an images, we need to specify slice parameters. In this example we will ice images into 256x256 grids overlap ratio of 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files = len(glob.glob(f\"{batch_output_directory}/*txt\"))\n",
    "n_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = n_files\n",
    "json_out =f\"{coco_annotations_path}/coco_annotations.json\"\n",
    "sliced_dir = sliced_images_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_coco(coco_path):\n",
    "    with open(coco_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    m = {}\n",
    "    for img in data[\"images\"]:\n",
    "        m[img[\"file_name\"]] = {\n",
    "            \"images\": [img],\n",
    "            \"annotations\": [],\n",
    "            \"categories\": data.get(\"categories\", [])\n",
    "        }\n",
    "    d = {img[\"id\"]: img[\"file_name\"] for img in data[\"images\"]}\n",
    "    for ann in data[\"annotations\"]:\n",
    "        fn = d[ann[\"image_id\"]]\n",
    "        m[fn][\"annotations\"].append(ann)\n",
    "    return m\n",
    "\n",
    "def process_file(args):\n",
    "    f, splitted, sliced_dir = args\n",
    "    name = Path(f).name\n",
    "    if name not in splitted:\n",
    "        return f\n",
    "    o = os.path.join(sliced_dir, Path(f).stem)\n",
    "    a = os.path.join(o, f\"{Path(f).stem}_sliced_annotations.json\")\n",
    "    if os.path.exists(o) and os.path.exists(a):\n",
    "        return None\n",
    "    t = os.path.join(sliced_dir, f\"temp_processing_{uuid.uuid4()}\")\n",
    "    try:\n",
    "        os.makedirs(t, exist_ok=True)\n",
    "        local_coco = os.path.join(t, \"annotation.json\")\n",
    "        with open(local_coco, \"w\") as w:\n",
    "            json.dump(splitted[name], w)\n",
    "        shutil.copy(f, t)\n",
    "        slice_coco(\n",
    "            coco_annotation_file_path=local_coco,\n",
    "            image_dir=t,\n",
    "            output_coco_annotation_file_name=f\"{Path(f).stem}_sliced_annotations\",\n",
    "            ignore_negative_samples=False,\n",
    "            output_dir=o,\n",
    "            slice_height=640,\n",
    "            slice_width=640,\n",
    "            overlap_height_ratio=0.2,\n",
    "            overlap_width_ratio=0.2,\n",
    "            min_area_ratio=0.1,\n",
    "            verbose=False\n",
    "        )\n",
    "    except Exception:\n",
    "        return f\n",
    "    finally:\n",
    "        if os.path.exists(t):\n",
    "            shutil.rmtree(t)\n",
    "    return None\n",
    "\n",
    "def run_processing(batch_output_directory, sliced_dir, coco_file, processes=4):\n",
    "    splitted = split_coco(coco_file)\n",
    "    image_files = [\n",
    "        x for x in glob.iglob(os.path.join(batch_output_directory, \"*\"))\n",
    "        if not x.lower().endswith(\".txt\")\n",
    "    ]\n",
    "    with Pool(processes=processes) as p:\n",
    "        r = p.map(\n",
    "            process_file,\n",
    "            [(f, splitted, sliced_dir) for f in image_files]\n",
    "        )\n",
    "    m = [x for x in r if x]\n",
    "    if m:\n",
    "        with open(\"missing_files.log\", \"w\") as w:\n",
    "            w.write(\"\\n\".join(m))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_files = run_processing(\n",
    "    batch_output_directory,\n",
    "    sliced_dir,\n",
    "    json_out,\n",
    "    processes=os.cpu_count()-2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert back to yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_folder(args):\n",
    "    folder_name, batch_output_directory, source_directory = args\n",
    "    batch_path = os.path.join(batch_output_directory, folder_name)\n",
    "    if not os.path.isdir(batch_path):\n",
    "        return\n",
    "    sliced_coco_path = os.path.join(\n",
    "        batch_path, f\"{os.path.basename(batch_path)}_sliced_annotations_coco.json\"\n",
    "    )\n",
    "    if not os.path.exists(sliced_coco_path):\n",
    "        return\n",
    "    coco = Coco.from_coco_dict_or_path(sliced_coco_path, image_dir=batch_path)\n",
    "    coco.export_as_yolov5(\n",
    "        output_dir=source_directory,\n",
    "        train_split_rate=1,\n",
    "        disable_symlink=True\n",
    "    )\n",
    "\n",
    "def export_all_sliced_to_yolo(batch_output_directory, source_directory, processes=4):\n",
    "    folders = sorted(os.listdir(batch_output_directory))\n",
    "    with Pool(processes=processes) as pool:\n",
    "        pool.map(\n",
    "            _process_folder,\n",
    "            [(f, batch_output_directory, source_directory) for f in folders]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_all_sliced_to_yolo(sliced_dir, yolo_format_dir, processes=os.cpu_count()-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize sliced annotations on sliced images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_random_images_with_yolo_annotations(source_directory, num_images=5):\n",
    "    image_files = []\n",
    "    for f in os.listdir(source_directory):\n",
    "        if f.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            image_files.append(os.path.join(source_directory, f))\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"No images found in:\", source_directory)\n",
    "        return\n",
    "    \n",
    "    selected_images = random.sample(image_files, min(num_images, len(image_files)))\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(selected_images), figsize=(16, 5))\n",
    "    if len(selected_images) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, img_path in zip(axes, selected_images):\n",
    "        img = Image.open(img_path)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        width, height = img.size\n",
    "\n",
    "        label_path = os.path.splitext(img_path)[0] + \".txt\"\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) != 5:\n",
    "                        continue\n",
    "                    cat_id = parts[0]\n",
    "                    x_c, y_c, w, h = map(float, parts[1:])\n",
    "                    x1 = int((x_c - w / 2) * width)\n",
    "                    y1 = int((y_c - h / 2) * height)\n",
    "                    x2 = int((x_c + w / 2) * width)\n",
    "                    y2 = int((y_c + h / 2) * height)\n",
    "                    draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n",
    "                    draw.text((x1, y1), f\"Class {cat_id}\", fill=\"red\")\n",
    "\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_images_with_yolo_annotations(f\"{yolo_format_dir}/train\", num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_dir = f\"{batch_output_directory.replace('/images','/full_dataset')}\"\n",
    "os.makedirs(full_dataset_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"cp -r {yolo_format_dir}/train {full_dataset_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"cd {full_dataset_dir} && rsync -a --remove-source-files train/ . > /dev/null 2>&1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rmdir(f\"{full_dataset_dir}/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f\"cp -r {images_train_source} {full_dataset_dir}\")\n",
    "os.system(f\"cp -r {images_val_source} {full_dataset_dir}\")\n",
    "os.system(f\"cp -r {labels_train_source} {full_dataset_dir}\")\n",
    "os.system(f\"cp -r {labels_val_source} {full_dataset_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f\"cd {full_dataset_dir} && rsync -a --remove-source-files train/ . > /dev/null 2>&1\")\n",
    "os.system(f\"cd {full_dataset_dir} && rsync -a --remove-source-files val/ . > /dev/null 2>&1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rmdir(f\"{full_dataset_dir}/train\")\n",
    "os.rmdir(f\"{full_dataset_dir}/val\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "super_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
