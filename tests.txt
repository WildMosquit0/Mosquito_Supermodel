============================= test session starts ==============================
platform linux -- Python 3.10.14, pytest-8.1.1, pluggy-1.5.0
rootdir: /home/ziv/git/Mosquito_Supermodel
plugins: anyio-4.3.0
collected 6 items

src/tests/test_yolo_detection_model.py .FF                               [ 50%]
src/tests/test_yolo_tracking_model.py .FF                                [100%]

=================================== FAILURES ===================================
______________________________ test_training_step ______________________________

dummy_detection_model = YOLODetectionModel(
  (model): YOLO(
    (model): DetectionModel(
      (model): Sequential(
        (0): Conv(
      ...         (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
)
dummy_batch = {'images': tensor([[[[-1.0438,  1.6304,  0.4101,  ...,  0.7389,  0.9995,  0.5266],
          [ 0.4649, -0.0161, -0.186....0515],
        [ 0.4727,  0.0354,  0.1586,  0.3386, -0.2758],
        [-0.4463,  0.6796,  0.6464, -0.7878,  0.5766]])}

    def test_training_step(dummy_detection_model, dummy_batch):
>       loss = dummy_detection_model.training_step(dummy_batch, batch_idx=0)

src/tests/test_yolo_detection_model.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = YOLODetectionModel(
  (model): YOLO(
    (model): DetectionModel(
      (model): Sequential(
        (0): Conv(
      ...         (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
)
batch = {'images': tensor([[[[-1.0438,  1.6304,  0.4101,  ...,  0.7389,  0.9995,  0.5266],
          [ 0.4649, -0.0161, -0.186....0515],
        [ 0.4727,  0.0354,  0.1586,  0.3386, -0.2758],
        [-0.4463,  0.6796,  0.6464, -0.7878,  0.5766]])}
batch_idx = 0

    def training_step(self, batch: Dict[str, Any], batch_idx: int):
        images = batch['images']
        # Direct training step using the forward method
        results = self.model(images)  # YOLOv8 internally handles loss
>       loss = results.loss if hasattr(results, 'loss') else torch.tensor(0.0)
E       NameError: name 'torch' is not defined

src/models/yolo_detection_model.py:17: NameError
----------------------------- Captured stdout call -----------------------------

WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.717136383056641. Dividing input by 255.
0: 256x256 (no detections), 13.6ms
1: 256x256 (no detections), 13.6ms
2: 256x256 (no detections), 13.6ms
3: 256x256 (no detections), 13.6ms
Speed: 0.0ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 256)
_____________________________ test_validation_step _____________________________

dummy_detection_model = YOLODetectionModel(
  (model): YOLO(
    (model): DetectionModel(
      (model): Sequential(
        (0): Conv(
      ...         (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
)
dummy_batch = {'images': tensor([[[[-2.4187e+00, -1.0441e-01, -4.1015e-01,  ..., -1.3054e+00,  1.0791e+00, -2.5798e+00],
          [....0522],
        [ 0.4782, -0.8442,  2.1028, -0.4258,  0.5129],
        [-2.1709,  0.5390,  0.8762,  0.6915, -0.2485]])}

    def test_validation_step(dummy_detection_model, dummy_batch):
>       val_output = dummy_detection_model.validation_step(dummy_batch, batch_idx=0)

src/tests/test_yolo_detection_model.py:26: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = YOLODetectionModel(
  (model): YOLO(
    (model): DetectionModel(
      (model): Sequential(
        (0): Conv(
      ...         (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
)
batch = {'images': tensor([[[[-2.4187e+00, -1.0441e-01, -4.1015e-01,  ..., -1.3054e+00,  1.0791e+00, -2.5798e+00],
          [....0522],
        [ 0.4782, -0.8442,  2.1028, -0.4258,  0.5129],
        [-2.1709,  0.5390,  0.8762,  0.6915, -0.2485]])}
batch_idx = 0

    def validation_step(self, batch: Dict[str, Any], batch_idx: int):
        images = batch['images']
        results = self.model(images)
>       val_loss = results.loss if hasattr(results, 'loss') else torch.tensor(0.0)
E       NameError: name 'torch' is not defined

src/models/yolo_detection_model.py:23: NameError
----------------------------- Captured stdout call -----------------------------

WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.576233863830566. Dividing input by 255.
0: 256x256 (no detections), 11.6ms
1: 256x256 (no detections), 11.6ms
2: 256x256 (no detections), 11.6ms
3: 256x256 (no detections), 11.6ms
Speed: 0.0ms preprocess, 11.6ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 256)
______________________________ test_training_step ______________________________

dummy_tracking_model = YOLOTrackingModel(
  (model): YOLO(
    (model): DetectionModel(
      (model): Sequential(
        (0): Conv(
       ...         (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
)
dummy_batch = {'images': tensor([[[[-1.5190e-01,  1.4809e-01, -8.9777e-01,  ...,  4.9089e-01, -6.1615e-01,  1.6170e+00],
          [....4650],
        [-0.0138, -0.9819,  1.0811, -0.2434,  0.3472],
        [ 1.2245, -0.7771,  0.2961, -0.3477, -2.1817]])}

    def test_training_step(dummy_tracking_model, dummy_batch):
>       loss = dummy_tracking_model.training_step(dummy_batch, batch_idx=0)

src/tests/test_yolo_tracking_model.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = YOLOTrackingModel(
  (model): YOLO(
    (model): DetectionModel(
      (model): Sequential(
        (0): Conv(
       ...         (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
)
batch = {'images': tensor([[[[-1.5190e-01,  1.4809e-01, -8.9777e-01,  ...,  4.9089e-01, -6.1615e-01,  1.6170e+00],
          [....4650],
        [-0.0138, -0.9819,  1.0811, -0.2434,  0.3472],
        [ 1.2245, -0.7771,  0.2961, -0.3477, -2.1817]])}
batch_idx = 0

    def training_step(self, batch: Dict[str, Any], batch_idx: int):
        images = batch['images']
        results = self.model(images)  # YOLOv8 internally handles loss
>       loss = results.loss if hasattr(results, 'loss') else torch.tensor(0.0)
E       NameError: name 'torch' is not defined

src/models/yolo_tracking_model.py:16: NameError
----------------------------- Captured stdout call -----------------------------

WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.803610801696777. Dividing input by 255.
0: 256x256 (no detections), 11.6ms
1: 256x256 (no detections), 11.6ms
2: 256x256 (no detections), 11.6ms
3: 256x256 (no detections), 11.6ms
Speed: 0.0ms preprocess, 11.6ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 256)
_____________________________ test_validation_step _____________________________

dummy_tracking_model = YOLOTrackingModel(
  (model): YOLO(
    (model): DetectionModel(
      (model): Sequential(
        (0): Conv(
       ...         (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
)
dummy_batch = {'images': tensor([[[[ 4.7111e-02,  5.4239e-01,  1.9972e+00,  ..., -1.2991e+00,  7.8509e-01, -2.4329e-01],
          [....2515],
        [ 0.9369, -0.0112,  0.8281,  1.8723,  0.3093],
        [ 0.9406, -0.4562,  1.2218,  0.5619, -2.0288]])}

    def test_validation_step(dummy_tracking_model, dummy_batch):
>       val_output = dummy_tracking_model.validation_step(dummy_batch, batch_idx=0)

src/tests/test_yolo_tracking_model.py:26: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = YOLOTrackingModel(
  (model): YOLO(
    (model): DetectionModel(
      (model): Sequential(
        (0): Conv(
       ...         (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
)
batch = {'images': tensor([[[[ 4.7111e-02,  5.4239e-01,  1.9972e+00,  ..., -1.2991e+00,  7.8509e-01, -2.4329e-01],
          [....2515],
        [ 0.9369, -0.0112,  0.8281,  1.8723,  0.3093],
        [ 0.9406, -0.4562,  1.2218,  0.5619, -2.0288]])}
batch_idx = 0

    def validation_step(self, batch: Dict[str, Any], batch_idx: int):
        images = batch['images']
        results = self.model(images)
>       val_loss = results.loss if hasattr(results, 'loss') else torch.tensor(0.0)
E       NameError: name 'torch' is not defined

src/models/yolo_tracking_model.py:22: NameError
----------------------------- Captured stdout call -----------------------------

WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.537734031677246. Dividing input by 255.
0: 256x256 (no detections), 14.8ms
1: 256x256 (no detections), 14.8ms
2: 256x256 (no detections), 14.8ms
3: 256x256 (no detections), 14.8ms
Speed: 0.0ms preprocess, 14.8ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 256)
=========================== short test summary info ============================
FAILED src/tests/test_yolo_detection_model.py::test_training_step - NameError...
FAILED src/tests/test_yolo_detection_model.py::test_validation_step - NameErr...
FAILED src/tests/test_yolo_tracking_model.py::test_training_step - NameError:...
FAILED src/tests/test_yolo_tracking_model.py::test_validation_step - NameErro...
========================= 4 failed, 2 passed in 8.25s ==========================
